{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":31137,"databundleVersionId":2671877,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-19T06:22:23.490837Z","iopub.execute_input":"2024-03-19T06:22:23.491237Z","iopub.status.idle":"2024-03-19T06:22:23.500172Z","shell.execute_reply.started":"2024-03-19T06:22:23.491206Z","shell.execute_reply":"2024-03-19T06:22:23.499149Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"/kaggle/input/recommended-system-for-amazon-icl-2021/train.csv\n/kaggle/input/recommended-system-for-amazon-icl-2021/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndtype = [(\"userId\", np.string_), (\"movieId\", np.string_), (\"rating\", np.int32)]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:22:23.502419Z","iopub.execute_input":"2024-03-19T06:22:23.502850Z","iopub.status.idle":"2024-03-19T06:22:23.513131Z","shell.execute_reply.started":"2024-03-19T06:22:23.502816Z","shell.execute_reply":"2024-03-19T06:22:23.512151Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/recommended-system-for-amazon-icl-2021/train.csv',dtype=dict(dtype))\ntrain_dataset.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:22:23.515042Z","iopub.execute_input":"2024-03-19T06:22:23.515589Z","iopub.status.idle":"2024-03-19T06:22:23.553603Z","shell.execute_reply.started":"2024-03-19T06:22:23.515556Z","shell.execute_reply":"2024-03-19T06:22:23.552140Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"           userId   productId  Rating\n0   AOPE42H34R0EC  B00000DM9W     5.0\n1  A1GI09JC6L0NF7  B00004SABJ     4.0\n2   AZLZII4AFX56R  B00000J579     3.0\n3  A34AHNT6GD9FWW  9888002198     5.0\n4  A2PXRAO5C1XTLW  0972683275     5.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>productId</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AOPE42H34R0EC</td>\n      <td>B00000DM9W</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A1GI09JC6L0NF7</td>\n      <td>B00004SABJ</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AZLZII4AFX56R</td>\n      <td>B00000J579</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A34AHNT6GD9FWW</td>\n      <td>9888002198</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A2PXRAO5C1XTLW</td>\n      <td>0972683275</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# 评分预测    1-5\nclass LFM(object):\n\n    def __init__(self, alpha, reg_p, reg_q, number_LatentFactors=10, number_epochs=10, columns=[\"uid\", \"iid\", \"rating\"]):\n        self.alpha = alpha # 学习率\n        self.reg_p = reg_p    # P矩阵正则\n        self.reg_q = reg_q    # Q矩阵正则\n        self.number_LatentFactors = number_LatentFactors  # 隐式类别数量\n        self.number_epochs = number_epochs    # 最大迭代次数\n        self.columns = columns\n\n    def fit(self, dataset):\n        '''\n        fit dataset\n        :param dataset: uid, iid, rating\n        :return:\n        '''\n\n        self.dataset = pd.DataFrame(dataset)\n\n        self.users_ratings = dataset.groupby(self.columns[0]).agg([list])[[self.columns[1], self.columns[2]]]\n        self.items_ratings = dataset.groupby(self.columns[1]).agg([list])[[self.columns[0], self.columns[2]]]\n\n        self.globalMean = self.dataset[self.columns[2]].mean()\n\n        self.P, self.Q = self.sgd()\n\n    def _init_matrix(self):\n        '''\n        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值\n        :return:\n        '''\n        # User-LF\n        P = dict(zip(\n            self.users_ratings.index,\n            np.random.rand(len(self.users_ratings), self.number_LatentFactors).astype(np.float32)\n        ))\n        # Item-LF\n        Q = dict(zip(\n            self.items_ratings.index,\n            np.random.rand(len(self.items_ratings), self.number_LatentFactors).astype(np.float32)\n        ))\n        return P, Q\n\n    def sgd(self):\n        '''\n        使用随机梯度下降，优化结果\n        :return:\n        '''\n        P, Q = self._init_matrix()\n\n        for i in range(self.number_epochs):\n            print(\"iter%d\"%i)\n            error_list = []\n            for uid, iid, r_ui in self.dataset.itertuples(index=False):\n                # User-LF P\n                ## Item-LF Q\n                v_pu = P[uid] #用户向量\n                v_qi = Q[iid] #物品向量\n                err = np.float32(r_ui - np.dot(v_pu, v_qi))\n\n                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)\n                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)\n                \n                P[uid] = v_pu \n                Q[iid] = v_qi\n\n                # for k in range(self.number_of_LatentFactors):\n                #     v_pu[k] += self.alpha*(err*v_qi[k] - self.reg_p*v_pu[k])\n                #     v_qi[k] += self.alpha*(err*v_pu[k] - self.reg_q*v_qi[k])\n\n                error_list.append(err ** 2)\n            print(np.sqrt(np.mean(error_list)))\n        return P, Q\n\n    def predict(self, uid, iid):\n        # 如果uid或iid不在，我们使用全剧平均分作为预测结果返回\n        if uid not in self.users_ratings.index or iid not in self.items_ratings.index:\n            return self.globalMean\n\n        p_u = self.P[uid]\n        q_i = self.Q[iid]\n\n        return np.dot(p_u, q_i)\n\n    def test(self,testset):\n        '''预测测试集数据'''\n        df=pd.DataFrame({\"Keys\":[],\"Rating\":[]})\n        i=0;\n        for uid, iid, _ in testset.itertuples(index=False):\n            pred_rating = self.predict(uid, iid)\n            pred_rating = round(pred_rating)\n            pred_rating = round(pred_rating,2)\n            new_row=pd.Series({\"Keys\":(uid,iid),\"Rating\":pred_rating})\n            df = pd.concat([df, new_row.to_frame().T])\n            i =i +1\n        df.to_csv('/kaggle/working/submission.csv',index=False)\n                \n           ","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:22:23.555366Z","iopub.execute_input":"2024-03-19T06:22:23.555804Z","iopub.status.idle":"2024-03-19T06:22:23.571274Z","shell.execute_reply.started":"2024-03-19T06:22:23.555777Z","shell.execute_reply":"2024-03-19T06:22:23.569246Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[33], line 97\u001b[0;36m\u001b[0m\n\u001b[0;31m    df.to_csv('/kaggle/working/submission.csv'，index=False)\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '，' (U+FF0C)\n"],"ename":"SyntaxError","evalue":"invalid character '，' (U+FF0C) (1641194699.py, line 97)","output_type":"error"}]},{"cell_type":"code","source":"test_dataset = pd.read_csv('/kaggle/input/recommended-system-for-amazon-icl-2021/test.csv',dtype=dict(dtype))\nlfm = LFM(0.02, 0.01, 0.01, 10, 50, [\"userId\",\"productId\",\"Rating\"])\nlfm.fit(train_dataset)\nlfm.test(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T06:22:23.572248Z","iopub.status.idle":"2024-03-19T06:22:23.572711Z","shell.execute_reply.started":"2024-03-19T06:22:23.572464Z","shell.execute_reply":"2024-03-19T06:22:23.572483Z"},"trusted":true},"execution_count":null,"outputs":[]}]}