{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表格预测器\n",
    "首先，导入 AutoGluon 的TabularPredictor和TabularDataset类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练数据从CSV 文件加载到 AutoGluon 数据集对象中。该对象本质上相当于Pandas DataFrame，并且相同的方法可以应用于两者。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29128</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>190483</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23950</th>\n",
       "      <td>72</td>\n",
       "      <td>?</td>\n",
       "      <td>188009</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13700</th>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>117310</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35248</th>\n",
       "      <td>21</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>596776</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24772</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>93283</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   workclass  fnlwgt      education  education-num  \\\n",
       "6118    51     Private   39264   Some-college             10   \n",
       "23204   58     Private   51662           10th              6   \n",
       "29590   40     Private  326310   Some-college             10   \n",
       "18116   37     Private  222450        HS-grad              9   \n",
       "33964   62     Private  109190      Bachelors             13   \n",
       "...    ...         ...     ...            ...            ...   \n",
       "29128   23     Private  190483      Bachelors             13   \n",
       "23950   72           ?  188009        7th-8th              4   \n",
       "13700   45     Private  117310        HS-grad              9   \n",
       "35248   21   Local-gov  596776   Some-college             10   \n",
       "24772   33     Private   93283      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "...                    ...               ...             ...     ...      ...   \n",
       "29128        Never-married             Sales       Own-child   White   Female   \n",
       "23950             Divorced                 ?   Not-in-family   White     Male   \n",
       "13700   Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "35248        Never-married      Adm-clerical       Own-child   White     Male   \n",
       "24772        Never-married    Prof-specialty       Unmarried   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  \n",
       "...             ...           ...             ...             ...     ...  \n",
       "29128             0             0              20   United-States   <=50K  \n",
       "23950             0             0              30   United-States   <=50K  \n",
       "13700             0             0              50   United-States    >50K  \n",
       "35248             0             0              40       Guatemala   <=50K  \n",
       "24772             0             0              40   United-States   <=50K  \n",
       "\n",
       "[500 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，我们从存储在云中的 CSV 文件加载数据。如果您已经将 CSV 文件下载到您自己的计算机上（例如，使用wget），您也可以指定本地文件路径。表中的每一行train_data对应于一个训练示例。在这个特定的数据集中，每一行对应一个人，列包含人口普查期间报告的各种特征。\n",
    "\n",
    "我们首先使用这些特征来预测这个人的收入是否超过 50,000 美元，记录在class这个表的列中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: [' >50K', ' <=50K']\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(f\"Unique classes: {list(train_data[label].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon 使用原始数据，这意味着您在拟合 AutoGluon 之前无需执行任何数据预处理。我们强烈建议您避免执行缺失值插补或单热编码等操作，因为 AutoGluon 具有专用逻辑来自动处理这些情况。您可以在特征工程教程中了解有关 AutoGluon 预处理的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练\n",
    "现在我们用一行代码初始化并拟合 AutoGluon 的 TabularPredictor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240316_180950\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240316_180950\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.3.0: Mon Jan 30 20:39:35 PST 2023; root:xnu-8792.81.3~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.39 GB / 8.00 GB (17.4%)\n",
      "Disk Space Avail:   51.53 GB / 228.27 GB (22.6%)\n",
      "===================================================\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1436.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240316_180950\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是这样！我们现在有了一个 TabularPredictor，它能够对新数据进行预测。\n",
    "\n",
    "预言\n",
    "接下来，加载单独的测试数据以演示如何在推理时对新示例进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "0             0             0              20   United-States   <=50K  \n",
       "1             0             0              45   United-States   <=50K  \n",
       "2             0          1887              60   United-States    >50K  \n",
       "3             0             0              30   United-States   <=50K  \n",
       "4             0             0              20   United-States   <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在可以使用经过训练的模型对新数据进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <=50K\n",
       "1     <=50K\n",
       "2      >50K\n",
       "3     <=50K\n",
       "4     <=50K\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "y_pred.head()  # Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.018874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983599</td>\n",
       "      <td>0.016401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478133</td>\n",
       "      <td>0.521867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994751</td>\n",
       "      <td>0.005249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.988539</td>\n",
       "      <td>0.011461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      <=50K      >50K\n",
       "0  0.981126  0.018874\n",
       "1  0.983599  0.016401\n",
       "2  0.478133  0.521867\n",
       "3  0.994751  0.005249\n",
       "4  0.988539  0.011461"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "y_pred_proba.head()  # Prediction Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估\n",
    "接下来，我们可以根据（标记的）测试数据评估预测器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8409253761899887,\n",
       " 'balanced_accuracy': 0.7475663839529563,\n",
       " 'mcc': 0.5345297121913682,\n",
       " 'roc_auc': 0.884716037791454,\n",
       " 'f1': 0.6296472831267874,\n",
       " 'precision': 0.7034078807241747,\n",
       " 'recall': 0.5698878343399483}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以单独评估每个模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.226020</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.226020</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.86</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.731228</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.731228</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.86</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.910008</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.178780</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.840925</td>\n",
       "      <td>0.83</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.045826</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.045826</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.590442</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.590442</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.507735</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.507735</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.835705</td>\n",
       "      <td>0.83</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.471932</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.471932</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834374</td>\n",
       "      <td>0.82</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.201569</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.201569</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.057406</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.190190</td>\n",
       "      <td>0.057406</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.190190</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.015583</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>2.594767</td>\n",
       "      <td>0.015583</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>2.594767</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.82</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.115061</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.658453</td>\n",
       "      <td>0.115061</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.658453</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>1.126437</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>1.126437</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0      RandomForestGini    0.842461       0.84    accuracy        0.069452   \n",
       "1               XGBoost    0.840925       0.86    accuracy        0.029019   \n",
       "2   WeightedEnsemble_L2    0.840925       0.86    accuracy        0.030143   \n",
       "3      RandomForestEntr    0.840925       0.83    accuracy        0.045826   \n",
       "4              LightGBM    0.839799       0.85    accuracy        0.010307   \n",
       "5            LightGBMXT    0.836421       0.83    accuracy        0.011586   \n",
       "6        NeuralNetTorch    0.835705       0.83    accuracy        0.030303   \n",
       "7        ExtraTreesGini    0.834374       0.82    accuracy        0.097729   \n",
       "8        ExtraTreesEntr    0.832839       0.81    accuracy        0.057406   \n",
       "9         LightGBMLarge    0.828949       0.83    accuracy        0.015583   \n",
       "10      NeuralNetFastAI    0.823626       0.82    accuracy        0.115061   \n",
       "11       KNeighborsUnif    0.725970       0.73    accuracy        0.019916   \n",
       "12       KNeighborsDist    0.695158       0.65    accuracy        0.017276   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.015696  0.226020                 0.069452                0.015696   \n",
       "1        0.003668  0.731228                 0.029019                0.003668   \n",
       "2        0.003964  0.910008                 0.001124                0.000296   \n",
       "3        0.015236  0.200196                 0.045826                0.015236   \n",
       "4        0.001976  0.590442                 0.010307                0.001976   \n",
       "5        0.002791  0.507735                 0.011586                0.002791   \n",
       "6        0.005052  0.471932                 0.030303                0.005052   \n",
       "7        0.015282  0.201569                 0.097729                0.015282   \n",
       "8        0.014712  0.190190                 0.057406                0.014712   \n",
       "9        0.002833  2.594767                 0.015583                0.002833   \n",
       "10       0.006909  0.658453                 0.115061                0.006909   \n",
       "11       0.024914  1.126437                 0.019916                0.024914   \n",
       "12       0.015911  0.003020                 0.017276                0.015911   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.226020            1       True          5  \n",
       "1            0.731228            1       True         10  \n",
       "2            0.178780            2       True         13  \n",
       "3            0.200196            1       True          6  \n",
       "4            0.590442            1       True          4  \n",
       "5            0.507735            1       True          3  \n",
       "6            0.471932            1       True         11  \n",
       "7            0.201569            1       True          7  \n",
       "8            0.190190            1       True          8  \n",
       "9            2.594767            1       True         12  \n",
       "10           0.658453            1       True          9  \n",
       "11           1.126437            1       True          1  \n",
       "12           0.003020            1       True          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载经过训练的预测器\n",
    "最后，我们可以通过调用TabularPredictor.load()并指定预测器工件在磁盘上的位置，在新会话（或新机器）中加载预测器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AutogluonModels/ag-20240316_180950'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.path  # The path on disk where the predictor is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictor by specifying the path it is saved to on disk.\n",
    "# You can control where it is saved to by setting the `path` parameter during init\n",
    "predictor = TabularPredictor.load(predictor.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在您已准备好在自己的表格数据集上尝试 AutoGluon！只要它们以 CSV 等流行格式存储，您应该只需 2 行代码即可实现强大的预测性能："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=<variable-name>).fit(train_data=<file-name>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：这个对TabularPredictor.fit()的简单调用适用于您的第一个原型模型。在后续部分中，我们将演示如何通过另外指定presets参数 tofit()和eval_metric参数 to来最大化预测性能TabularPredictor()。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit() 的描述\n",
    "在此我们讨论期间发生的事情fit()。\n",
    "\n",
    "由于变量只有两个可能的值class，因此这是一个二元分类问题，适当的性能指标是准确性。AutoGluon 会自动推断这一点以及每个特征的类型（即哪些列包含连续数字与离散类别）。AutoGluon 还可以自动处理常见问题，例如丢失数据和重新缩放特征值。\n",
    "\n",
    "我们没有指定单独的验证数据，因此 AutoGluon 自动选择数据的随机训练/验证分割。用于验证的数据与训练数据分开，用于确定产生最佳结果的模型和超参数值。AutoGluon 不只是单个模型，而是训练多个模型并将它们集成在一起以获得卓越的预测性能。\n",
    "\n",
    "默认情况下，AutoGluon 尝试拟合各种类型的模型，包括神经网络和树集成。每种类型的模型都有各种超参数，传统上用户必须指定这些超参数。AutoGluon 使这个过程自动化。\n",
    "\n",
    "AutoGluon 自动迭代地测试超参数值，以在验证数据上产生最佳性能。这涉及在不同的超参数设置下反复训练模型并评估其性能。此过程可能需要大量计算，因此使用Rayfit()跨多个线程并行化此过程。要控制运行时，您可以指定各种参数，如后续深入教程中演示的那样。fit()time_limit\n",
    "\n",
    "我们可以查看 AutoGluon 自动推断出我们的预测任务的哪些属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon 正确地将我们的预测问题识别为二元分类任务，并决定诸如此类的变量age应表示为整数，而诸如此类的变量workclass应表示为分类对象。该feature_metadata属性允许您在预处理后查看每个预测变量的推断数据类型（这是其原始数据类型；如果通过特征工程生成，某些特征还可能与其他特殊数据类型相关联，例如日期时间/文本列的数字表示） 。\n",
    "\n",
    "要将数据转换为 AutoGluon 的内部表示，我们可以执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>169085</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>226203</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>54260</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>176262</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>241185</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  sex  capital-gain  capital-loss  \\\n",
       "0   31  169085              7    0             0             0   \n",
       "1   17  226203              8    1             0             0   \n",
       "2   47   54260             11    1             0          1887   \n",
       "3   21  176262             10    0             0             0   \n",
       "4   17  241185              8    1             0             0   \n",
       "\n",
       "   hours-per-week workclass education marital-status occupation relationship  \\\n",
       "0              20         3         1              1         10            5   \n",
       "1              45         5         2              3         10            3   \n",
       "2              60         3         7              1          3            0   \n",
       "3              30         3        13              3          3            3   \n",
       "4              20         3         2              3          8            3   \n",
       "\n",
       "  race native-country  \n",
       "0    4             14  \n",
       "1    4             14  \n",
       "2    4             14  \n",
       "3    4             14  \n",
       "4    4             14  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_transform = predictor.transform_features(test_data)\n",
    "test_data_transform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意预处理后数据是如何纯粹数字的（尽管分类特征仍将被视为分类下游）。\n",
    "\n",
    "为了更好地理解我们训练的预测器，我们可以通过TabularPredictor.feature_importance()估计每个特征的总体重要性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n",
      "\t4.04s\t= Expected runtime (0.81s per shuffle set)\n",
      "\t1.74s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>3.698489e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058608</td>\n",
       "      <td>0.042992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.03852</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>1.565361e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.033748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.02968</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>5.063512e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032452</td>\n",
       "      <td>0.026908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>1.490440e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.009133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.01172</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>1.369430e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019902</td>\n",
       "      <td>0.003538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>1.406849e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.00472</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>3.967984e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>3.959537e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1.155921e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0.00108</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>1.820562e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>-0.003780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>6.012167e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>-0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>1.383281e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>-0.002446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>1.442554e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>-0.002212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>6.352320e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>-0.000670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev       p_value  n  p99_high   p99_low\n",
       "marital-status     0.05080  0.003792  3.698489e-06  5  0.058608  0.042992\n",
       "capital-gain       0.03852  0.002318  1.565361e-06  5  0.043292  0.033748\n",
       "education-num      0.02968  0.001346  5.063512e-07  5  0.032452  0.026908\n",
       "age                0.01500  0.002850  1.490440e-04  5  0.020867  0.009133\n",
       "hours-per-week     0.01172  0.003974  1.369430e-03  5  0.019902  0.003538\n",
       "occupation         0.00528  0.001803  1.406849e-03  5  0.008993  0.001567\n",
       "relationship       0.00472  0.001154  3.967984e-04  5  0.007096  0.002344\n",
       "native-country     0.00144  0.000654  3.959537e-03  5  0.002787  0.000093\n",
       "capital-loss       0.00128  0.000415  1.155921e-03  5  0.002134  0.000426\n",
       "fnlwgt             0.00108  0.002361  1.820562e-01  5  0.005940 -0.003780\n",
       "sex                0.00096  0.001090  6.012167e-02  5  0.003204 -0.001284\n",
       "workclass          0.00092  0.001635  1.383281e-01  5  0.004286 -0.002446\n",
       "education          0.00080  0.001463  1.442554e-01  5  0.003812 -0.002212\n",
       "race               0.00048  0.000559  6.352320e-02  5  0.001630 -0.000670"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该importance列是对如果从数据中删除该功能，评估指标分数将下降的量的估计。负值importance意味着如果删除特征后重新拟合可能会改善结果。\n",
    "\n",
    "当我们调用 时predict()，AutoGluon 会自动使用在验证数据上显示最佳性能的模型（即加权集成）进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以指定使用哪个模型进行预测，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(test_data, model='LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNeighborsUnif',\n",
       " 'KNeighborsDist',\n",
       " 'LightGBMXT',\n",
       " 'LightGBM',\n",
       " 'RandomForestGini',\n",
       " 'RandomForestEntr',\n",
       " 'ExtraTreesGini',\n",
       " 'ExtraTreesEntr',\n",
       " 'NeuralNetFastAI',\n",
       " 'XGBoost',\n",
       " 'NeuralNetTorch',\n",
       " 'LightGBMLarge',\n",
       " 'WeightedEnsemble_L2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述预测性能的分数基于默认评估指标（二元分类的准确性）。某些应用程序中的性能可能通过与 AutoGluon 默认优化的指标不同的指标来衡量。如果您知道应用程序中重要的指标，则应通过eval_metric参数指定它，如下一节所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预设\n",
    "AutoGluon 附带了多种预设，可以.fit通过presets参数在调用中指定。medium_quality默认情况下使用它来鼓励初始原型设计，但如果需要认真使用，则应使用其他预设。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们建议用户首先medium_quality了解问题并识别任何与数据相关的问题。如果medium_quality训练时间太长，请考虑在此原型设计阶段对训练数据进行二次采样。\n",
    "一旦你感觉舒服了，下一步就可以尝试best_quality。确保指定的time_limit值至少是 中使用的值的16 倍medium_quality。完成后，您应该拥有一个非常强大的解决方案，通常比medium_quality.\n",
    "请务必考虑保留 AutoGluon 在训练期间从未见过的测试数据，以确保模型在性能方面达到预期的效果。\n",
    "一旦您评估了best_quality和medium_quality，请检查其中一个是否满足您的需求。如果两者都没有，请考虑尝试high_quality和/或good_quality。\n",
    "如果没有一个预设满足要求，请参阅预测表中的列 - 深入了解更高级的 AutoGluon 选项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大化预测性能\n",
    "注意：fit()如果您正在对 AutoGluon-Tabular 进行基准测试或希望最大限度地提高其准确性，则不应使用完全默认的参数进行调用！为了获得 AutoGluon 的最佳预测准确性，您通常应该像这样使用它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240317_030844\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 60 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240317_030844/ds_sub_fit/sub_fit_ho.\n",
      "2024-03-17 11:08:44,978\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Beginning AutoGluon training ... Time limit = 15s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240317_030844/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.3.0: Mon Jan 30 20:39:35 PST 2023; root:xnu-8792.81.3~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.24 GB / 8.00 GB (15.5%)\n",
      "Disk Space Avail:   51.69 GB / 228.27 GB (22.6%)\n",
      "===================================================\n",
      "Train Data Rows:    444\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1272.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 9.83s of the 14.74s of remaining time.\n",
      "\t0.5271\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 9.79s of the 14.7s of remaining time.\n",
      "\t0.5389\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.76s of the 14.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/debugpy/_vendored/force_pydevd.py:18: UserWarning: incompatible copy of pydevd already imported:\n",
      " /Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/pydevd_plugins/extensions/pydevd_plugin_omegaconf.py\n",
      "  warnings.warn(msg + ':\\n {}'.format('\\n  '.join(_unvendored)))\n",
      "\t0.8895\t = Validation score   (roc_auc)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3.16s of the 8.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\t0.8693\t = Validation score   (roc_auc)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.76s of the 3.76s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.8895\t = Validation score   (roc_auc)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3.48s of the 3.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t0.8782\t = Validation score   (roc_auc)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.76s of the -0.73s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.8895\t = Validation score   (roc_auc)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.87s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240317_030844/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                   model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBMXT_BAG_L2       0.925203   0.878189     roc_auc        0.151483       0.186186  3.029363                 0.029176                0.064626           1.584801            2       True          6\n",
      "1      LightGBMXT_BAG_L1       0.918699   0.889480     roc_auc        0.045484       0.050900  0.836583                 0.045484                0.050900           0.836583            1       True          3\n",
      "2    WeightedEnsemble_L3       0.918699   0.889480     roc_auc        0.046502       0.051212  0.959530                 0.001018                0.000311           0.122947            3       True          7\n",
      "3    WeightedEnsemble_L2       0.918699   0.889480     roc_auc        0.046786       0.053197  1.082883                 0.001302                0.002297           0.246300            2       True          5\n",
      "4        LightGBM_BAG_L1       0.897561   0.869264     roc_auc        0.027060       0.023806  0.601169                 0.027060                0.023806           0.601169            1       True          4\n",
      "5  KNeighborsUnif_BAG_L1       0.573171   0.527070     roc_auc        0.025579       0.025332  0.004802                 0.025579                0.025332           0.004802            1       True          1\n",
      "6  KNeighborsDist_BAG_L1       0.556098   0.538940     roc_auc        0.024184       0.021521  0.002008                 0.024184                0.021521           0.002008            1       True          2\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 16 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 44 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 44s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240317_030844\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.3.0: Mon Jan 30 20:39:35 PST 2023; root:xnu-8792.81.3~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.76 GB / 8.00 GB (21.9%)\n",
      "Disk Space Avail:   50.69 GB / 228.27 GB (22.2%)\n",
      "===================================================\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1794.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 29.27s of the 43.91s of remaining time.\n",
      "\t0.5196\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 29.24s of the 43.87s of remaining time.\n",
      "\t0.537\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 29.21s of the 43.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.8912\t = Validation score   (roc_auc)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 25.49s of the 40.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\t0.8799\t = Validation score   (roc_auc)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 20.41s of the 35.04s of remaining time.\n",
      "\t0.8869\t = Validation score   (roc_auc)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 19.94s of the 34.57s of remaining time.\n",
      "\t0.8893\t = Validation score   (roc_auc)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 19.55s of the 34.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=50236, ip=127.0.0.1)\n",
      "ModuleNotFoundError: No module named 'catboost'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=50236, ip=127.0.0.1)\n",
      "  File \"/Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 95, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/Users/ganxing/anaconda3/envs/ai/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 71, in try_import_catboost\n",
      "    raise ImportError()\n",
      "ImportError\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 17.46s of the 32.1s of remaining time.\n",
      "\t0.8931\t = Validation score   (roc_auc)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 17.06s of the 31.7s of remaining time.\n",
      "\t0.8875\t = Validation score   (roc_auc)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 16.67s of the 31.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "2024-03-17 11:09:18,128\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-03-17 11:09:18,140\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-03-17 11:09:18,147\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-03-17 11:09:18,155\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-03-17 11:09:18,163\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-03-17 11:09:18,176\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-03-17 11:09:18,178\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8696\t = Validation score   (roc_auc)\n",
      "\t5.04s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 9.67s of the 24.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t0.8796\t = Validation score   (roc_auc)\n",
      "\t7.64s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 43.92s of the 2.31s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L1': 0.374, 'NeuralNetFastAI_BAG_L1': 0.308, 'LightGBMXT_BAG_L1': 0.209, 'RandomForestGini_BAG_L1': 0.088, 'RandomForestEntr_BAG_L1': 0.022}\n",
      "\t0.9047\t = Validation score   (roc_auc)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 43.92s of the -2.35s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L1': 0.374, 'NeuralNetFastAI_BAG_L1': 0.308, 'LightGBMXT_BAG_L1': 0.209, 'RandomForestGini_BAG_L1': 0.088, 'RandomForestEntr_BAG_L1': 0.022}\n",
      "\t0.9047\t = Validation score   (roc_auc)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 46.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240317_030844\")\n"
     ]
    }
   ],
   "source": [
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该命令实施以下策略以最大限度地提高准确性：\n",
    "\n",
    "指定参数presets='best_quality'，它允许 AutoGluon 基于stacking/bagging自动构造强大的模型集成，并且如果给予足够的训练时间，将大大改善结果预测。默认值presets是'medium_quality'，它产生的模型精度较低，但有利于更快的原型设计。使用presets，您可以灵活地优先考虑预测准确性与训练/推理速度。例如，如果您不太关心预测性能并希望快速部署基本模型，请考虑使用：。presets=['good_quality', 'optimize_for_deployment']\n",
    "\n",
    "eval_metric如果TabularPredictor()您知道将使用什么指标来评估应用程序中的预测，请提供参数。您可能使用的其他一些非默认指标包括：（'f1'用于二元分类）、'roc_auc'（用于二元分类）、'log_loss'（用于分类）、'mean_absolute_error'（用于回归）、'median_absolute_error'（用于回归）。您还可以定义自己的自定义指标函数。有关更多信息，请参阅向 AutoGluon 添加自定义指标。\n",
    "\n",
    "包含您的所有数据并且train_data不提供tuning_data（AutoGluon 将更智能地分割数据以满足其需求）。\n",
    "\n",
    "不要指定hyperparameter_tune_kwargs参数（与直觉相反，超参数调整并不是花费有限训练时间预算的最佳方式，因为模型集成通常更优越）。hyperparameter_tune_kwargs我们建议您仅在您的目标是部署单个模型而不是整体时使用。\n",
    "\n",
    "不要指定hyperparameters参数（允许 AutoGluon 自适应地选择要使用的模型/超参数）。\n",
    "\n",
    "设置time_limit为您愿意等待的最长时间（以秒为单位）。fit()AutoGluon 的预测性能随着运行时间的延长而提高。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
